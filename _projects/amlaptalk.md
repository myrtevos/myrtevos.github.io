---
layout: post
title: Webcam eye tracking
description: Replication study
---

| *Comparing Infrared and Webcam-based Eye Tracking in the Visual World Paradigm*
| Myrte Vos, Sergey Minor, Gillian Ramchand
| University of Troms√∏

In 2021, my coauthors and I replicated one of our earlier infrared eye tracking experiments with a fully browser-based methodology, to see how the quality of the data compared. Good news: webcam eye tracking is accurate enough for Visual World experiments!

The preprint of that paper is available at [PsyArXiv](https://psyarxiv.com/36skd/){:target="_blank"}, and all the associated analysis and experiment code, stimuli, and raw data is available at [OSF](https://osf.io/m395q/){:target="_blank"}. If you want, you can also try a demo version of our experiment [here](https://uit-jatos-test.azurewebsites.net/publix/1GMNfXCz69T){:target="_blank"}!

On September 4, 2021, I gave a 20-minute talk about this work at [Architectures and Mechanisms for Language Processing](www.amlap.org){:target="_blank"}, a conference highlighting interdisciplinary psycholinguistic research. 

Here's a link to the [abstract](https://amlap2021.github.io/program/126.pdf){:target="_blank"} for this talk.

<iframe width="560" height="315" src="https://www.youtube.com/embed/BeaF5lNGfmU" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>


[Back](https://myrtevos.github.io/projects/)
