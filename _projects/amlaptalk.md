---
layout: post
title: AMLaP talk 2021
description: Comparing infrared and webcam-based eye tracking in the Visual World Paradigm
---

| *Comparing Infrared and Webcam-based Eye Tracking in the Visual World Paradigm*
| Myrte Vos, Sergey Minor, Gillian Ramchand
| University of Troms√∏

On September 4, 2021, I gave a 20-minute talk at [Architectures and Mechanisms for Language Processing](www.amlap.org), a conference highlighting interdisciplinary psycholinguistic research. My coauthors and I had replicated one of our earlier infrared eye tracking experiments with a fully browser-based methodology, to see how the quality of the data compared. Good news: webcam eye tracking is accurate enough for Visual World experiments!

Here's a link to the [abstract](https://amlap2021.github.io/program/126.pdf) for this talk.

<iframe width="560" height="315" src="https://www.youtube.com/embed/BeaF5lNGfmU" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>


[Back](https://myrtevos.github.io/projects/)
